{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 01 - f(x) Function Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Dense Network to solve the following problem: \n",
    "Addition of 2 numbers between 0-100\n",
    "Remove certain numbers eg. 50 and make sure that the network can still generalize.\n",
    "Make it Classification rather than Regression\n",
    "Play with the network size, hyper parameters, and activation functions\n",
    "You need to make a dataset on your own too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from random import shuffle\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.6\n",
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_max, y_max = 100, 100 # the maximum value of x and y\n",
    "test_list = [16, 32, 48, 64, 80, 96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_classes = x_max + y_max + 1 # output class\n",
    "num_data = 1000000 # number of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Generate training data using random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_random_data(seed = 0):\n",
    "    z = []    \n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "    t = [] # validation data\n",
    "    for i in range(0,num_data):\n",
    "        v1 = np.random.randint(0,x_max+1)\n",
    "        v2 = np.random.randint(0,y_max+1)\n",
    "        if v1 in test_list or v2 in test_list:\n",
    "            t.append((v1,v2,v1+v2))\n",
    "            continue\n",
    "        z.append((v1,v2,v1+v2))\n",
    "    z = z + t\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = generate_random_data()\n",
    "\n",
    "# set the dataset as numpy array\n",
    "x=np.array( [v[0:2] for v in z] ).astype('float32')\n",
    "y=np.array( [v[2:][0] for v in z] ).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Normalize the training data to be the range of [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = x / x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hot encoding\n",
    "yy = to_categorical(y, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Set 75% for training data and 25% for validation data and prepare the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split train and validation data\n",
    "n_train = int( 0.75 * num_data ) \n",
    "x_train = x[0:n_train,]\n",
    "x_test = x[n_train:,]\n",
    "y_train = yy[0:n_train,] \n",
    "y_test = yy[n_train:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup hyperparameter for dense layer\n",
    "n_input = 2 # x + y -- two input dataset\n",
    "n_hidden_1 = 200 # layer - 1\n",
    "n_hidden_2 = 150 # layer - 2\n",
    "n_hidden_3 = 100 # layer - 3\n",
    "n_hidden_4 = 50 # layer - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Inp = Input(shape=(2,))\n",
    "x = Dense( n_hidden_1, activation = 'relu', name = 'Dense_1')(Inp)\n",
    "x = Dense( n_hidden_2, activation = 'relu', name = 'Dense_2')(x)\n",
    "x = Dense( n_hidden_3, activation = 'relu', name = 'Dense_3')(x)\n",
    "x = Dense( n_hidden_4, activation = 'relu', name = 'Dense_4')(x)\n",
    "output = Dense( n_classes, activation = 'softmax', name = 'Dense_out')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Model(Inp, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "Dense_1 (Dense)              (None, 200)               600       \n",
      "_________________________________________________________________\n",
      "Dense_2 (Dense)              (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "Dense_3 (Dense)              (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "Dense_4 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "Dense_out (Dense)            (None, 201)               10251     \n",
      "=================================================================\n",
      "Total params: 61,151\n",
      "Trainable params: 61,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_epochs = 400\n",
    "batch_sizes = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We introduce a function to allow changing the learning rate at different stage of epochs\n",
    "def step_decay(epoch):\n",
    "    if epoch<20:\n",
    "        return 0.002\n",
    "    if epoch<60:\n",
    "        return 0.001\n",
    "    return 0.0005\n",
    "\n",
    "lrate=LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam()\n",
    "model.compile( loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 750000 samples, validate on 250000 samples\n",
      "Epoch 1/400\n",
      "750000/750000 [==============================] - 8s - loss: 5.2165 - acc: 0.0073 - val_loss: 5.0610 - val_acc: 0.0086\n",
      "Epoch 2/400\n",
      "750000/750000 [==============================] - 5s - loss: 4.8572 - acc: 0.0124 - val_loss: 4.5048 - val_acc: 0.0214\n",
      "Epoch 3/400\n",
      "750000/750000 [==============================] - 4s - loss: 4.1309 - acc: 0.0480 - val_loss: 3.7113 - val_acc: 0.0811\n",
      "Epoch 4/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.4122 - acc: 0.1140 - val_loss: 3.1750 - val_acc: 0.1221\n",
      "Epoch 5/400\n",
      "750000/750000 [==============================] - 5s - loss: 2.9723 - acc: 0.1577 - val_loss: 2.8328 - val_acc: 0.1849\n",
      "Epoch 6/400\n",
      "750000/750000 [==============================] - 5s - loss: 2.7142 - acc: 0.1930 - val_loss: 2.6490 - val_acc: 0.2069\n",
      "Epoch 7/400\n",
      "750000/750000 [==============================] - 5s - loss: 2.5350 - acc: 0.2214 - val_loss: 2.4798 - val_acc: 0.2456\n",
      "Epoch 8/400\n",
      "750000/750000 [==============================] - 5s - loss: 2.4092 - acc: 0.2395 - val_loss: 2.3660 - val_acc: 0.2742\n",
      "Epoch 9/400\n",
      "750000/750000 [==============================] - 5s - loss: 2.3119 - acc: 0.2635 - val_loss: 2.2964 - val_acc: 0.2898\n",
      "Epoch 10/400\n",
      "750000/750000 [==============================] - 4s - loss: 2.2340 - acc: 0.2792 - val_loss: 2.2094 - val_acc: 0.2707\n",
      "Epoch 11/400\n",
      "750000/750000 [==============================] - 4s - loss: 2.1644 - acc: 0.2983 - val_loss: 2.1705 - val_acc: 0.3086\n",
      "Epoch 12/400\n",
      "750000/750000 [==============================] - 4s - loss: 2.1285 - acc: 0.2914 - val_loss: 2.1738 - val_acc: 0.2471\n",
      "Epoch 13/400\n",
      "750000/750000 [==============================] - 4s - loss: 2.0878 - acc: 0.3000 - val_loss: 2.0749 - val_acc: 0.2812\n",
      "Epoch 14/400\n",
      "750000/750000 [==============================] - 4s - loss: 2.0073 - acc: 0.3194 - val_loss: 1.9956 - val_acc: 0.3691\n",
      "Epoch 15/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.9452 - acc: 0.3537 - val_loss: 1.9758 - val_acc: 0.3002\n",
      "Epoch 16/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.9182 - acc: 0.3459 - val_loss: 1.9073 - val_acc: 0.3457\n",
      "Epoch 17/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.9101 - acc: 0.3452 - val_loss: 1.9534 - val_acc: 0.3297\n",
      "Epoch 18/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.9519 - acc: 0.3522 - val_loss: 2.0478 - val_acc: 0.3122\n",
      "Epoch 19/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.9835 - acc: 0.3514 - val_loss: 2.0246 - val_acc: 0.3412\n",
      "Epoch 20/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.8943 - acc: 0.3500 - val_loss: 1.8684 - val_acc: 0.3902\n",
      "Epoch 21/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.7374 - acc: 0.5031 - val_loss: 1.7356 - val_acc: 0.5642\n",
      "Epoch 22/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.6869 - acc: 0.5866 - val_loss: 1.7032 - val_acc: 0.6474\n",
      "Epoch 23/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.6635 - acc: 0.6176 - val_loss: 1.6830 - val_acc: 0.6277\n",
      "Epoch 24/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.6436 - acc: 0.6193 - val_loss: 1.6636 - val_acc: 0.6482\n",
      "Epoch 25/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.6253 - acc: 0.6327 - val_loss: 1.6467 - val_acc: 0.6191\n",
      "Epoch 26/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.6079 - acc: 0.6196 - val_loss: 1.6295 - val_acc: 0.6242\n",
      "Epoch 27/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.5889 - acc: 0.6114 - val_loss: 1.6115 - val_acc: 0.5713\n",
      "Epoch 28/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.5721 - acc: 0.6207 - val_loss: 1.5930 - val_acc: 0.5946\n",
      "Epoch 29/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.5545 - acc: 0.6133 - val_loss: 1.5743 - val_acc: 0.6001\n",
      "Epoch 30/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.5371 - acc: 0.6189 - val_loss: 1.5591 - val_acc: 0.5893\n",
      "Epoch 31/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.5215 - acc: 0.6053 - val_loss: 1.5565 - val_acc: 0.5852\n",
      "Epoch 32/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.5061 - acc: 0.6039 - val_loss: 1.5324 - val_acc: 0.6123\n",
      "Epoch 33/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.4916 - acc: 0.6093 - val_loss: 1.5094 - val_acc: 0.6296\n",
      "Epoch 34/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.4749 - acc: 0.6195 - val_loss: 1.4944 - val_acc: 0.5925\n",
      "Epoch 35/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.4617 - acc: 0.6110 - val_loss: 1.4759 - val_acc: 0.5985\n",
      "Epoch 36/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.4450 - acc: 0.6151 - val_loss: 1.4525 - val_acc: 0.6667\n",
      "Epoch 37/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.4309 - acc: 0.6147 - val_loss: 1.4613 - val_acc: 0.5876\n",
      "Epoch 38/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.4175 - acc: 0.6111 - val_loss: 1.4385 - val_acc: 0.6357\n",
      "Epoch 39/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.4049 - acc: 0.6230 - val_loss: 1.4223 - val_acc: 0.6120\n",
      "Epoch 40/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.3907 - acc: 0.6196 - val_loss: 1.4167 - val_acc: 0.6180\n",
      "Epoch 41/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.3833 - acc: 0.6206 - val_loss: 1.3949 - val_acc: 0.6391\n",
      "Epoch 42/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.3684 - acc: 0.6164 - val_loss: 1.3834 - val_acc: 0.6312\n",
      "Epoch 43/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.3547 - acc: 0.6236 - val_loss: 1.3892 - val_acc: 0.6132\n",
      "Epoch 44/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.3545 - acc: 0.6029 - val_loss: 1.4060 - val_acc: 0.5949\n",
      "Epoch 45/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.3494 - acc: 0.6060 - val_loss: 1.3547 - val_acc: 0.6378\n",
      "Epoch 46/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.3268 - acc: 0.6363 - val_loss: 1.3626 - val_acc: 0.6186\n",
      "Epoch 47/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.3086 - acc: 0.6393 - val_loss: 1.3580 - val_acc: 0.5994\n",
      "Epoch 48/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.3139 - acc: 0.6185 - val_loss: 1.3297 - val_acc: 0.6287\n",
      "Epoch 49/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.3000 - acc: 0.6205 - val_loss: 1.3377 - val_acc: 0.5990\n",
      "Epoch 50/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.2867 - acc: 0.6218 - val_loss: 1.3236 - val_acc: 0.5943\n",
      "Epoch 51/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.2780 - acc: 0.6342 - val_loss: 1.3063 - val_acc: 0.6307\n",
      "Epoch 52/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.2640 - acc: 0.6403 - val_loss: 1.2963 - val_acc: 0.6268\n",
      "Epoch 53/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.2441 - acc: 0.6582 - val_loss: 1.2799 - val_acc: 0.6441\n",
      "Epoch 54/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.2355 - acc: 0.6689 - val_loss: 1.2758 - val_acc: 0.6648\n",
      "Epoch 55/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.2312 - acc: 0.6682 - val_loss: 1.2823 - val_acc: 0.6201\n",
      "Epoch 56/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.2485 - acc: 0.6390 - val_loss: 1.3170 - val_acc: 0.6343\n",
      "Epoch 57/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.2402 - acc: 0.6343 - val_loss: 1.2541 - val_acc: 0.6165\n",
      "Epoch 58/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.2197 - acc: 0.6463 - val_loss: 1.2152 - val_acc: 0.6717\n",
      "Epoch 59/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.1860 - acc: 0.6811 - val_loss: 1.2319 - val_acc: 0.6563\n",
      "Epoch 60/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.1788 - acc: 0.6778 - val_loss: 1.2312 - val_acc: 0.6584\n",
      "Epoch 61/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.1526 - acc: 0.7496 - val_loss: 1.1634 - val_acc: 0.7942\n",
      "Epoch 62/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.1329 - acc: 0.8018 - val_loss: 1.1582 - val_acc: 0.7951\n",
      "Epoch 63/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.1242 - acc: 0.8042 - val_loss: 1.1521 - val_acc: 0.8183\n",
      "Epoch 64/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.1197 - acc: 0.8033 - val_loss: 1.1459 - val_acc: 0.8218\n",
      "Epoch 65/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.1140 - acc: 0.7993 - val_loss: 1.1445 - val_acc: 0.7930\n",
      "Epoch 66/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.1098 - acc: 0.8097 - val_loss: 1.1391 - val_acc: 0.8253\n",
      "Epoch 67/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.1034 - acc: 0.8111 - val_loss: 1.1336 - val_acc: 0.8075\n",
      "Epoch 68/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0985 - acc: 0.8101 - val_loss: 1.1249 - val_acc: 0.8309\n",
      "Epoch 69/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0962 - acc: 0.7936 - val_loss: 1.1266 - val_acc: 0.8060\n",
      "Epoch 70/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0923 - acc: 0.8105 - val_loss: 1.1196 - val_acc: 0.8170\n",
      "Epoch 71/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0861 - acc: 0.8101 - val_loss: 1.1124 - val_acc: 0.8508\n",
      "Epoch 72/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.0803 - acc: 0.8179 - val_loss: 1.1108 - val_acc: 0.7687\n",
      "Epoch 73/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.0748 - acc: 0.8141 - val_loss: 1.1009 - val_acc: 0.8464\n",
      "Epoch 74/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.0687 - acc: 0.8280 - val_loss: 1.1005 - val_acc: 0.7879\n",
      "Epoch 75/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.0659 - acc: 0.8084 - val_loss: 1.0950 - val_acc: 0.8096\n",
      "Epoch 76/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.0613 - acc: 0.8112 - val_loss: 1.0895 - val_acc: 0.8176\n",
      "Epoch 77/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.0567 - acc: 0.8080 - val_loss: 1.0868 - val_acc: 0.7958\n",
      "Epoch 78/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.0518 - acc: 0.8069 - val_loss: 1.0854 - val_acc: 0.8160\n",
      "Epoch 79/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.0467 - acc: 0.8184 - val_loss: 1.0768 - val_acc: 0.7878\n",
      "Epoch 80/400\n",
      "750000/750000 [==============================] - 4s - loss: 1.0423 - acc: 0.8070 - val_loss: 1.0708 - val_acc: 0.8083\n",
      "Epoch 81/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0389 - acc: 0.8112 - val_loss: 1.0677 - val_acc: 0.8008\n",
      "Epoch 82/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0349 - acc: 0.8029 - val_loss: 1.0668 - val_acc: 0.7813\n",
      "Epoch 83/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0301 - acc: 0.8134 - val_loss: 1.0549 - val_acc: 0.8422\n",
      "Epoch 84/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0246 - acc: 0.8037 - val_loss: 1.0549 - val_acc: 0.8131\n",
      "Epoch 85/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0200 - acc: 0.8201 - val_loss: 1.0497 - val_acc: 0.7956\n",
      "Epoch 86/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0143 - acc: 0.8160 - val_loss: 1.0424 - val_acc: 0.8222\n",
      "Epoch 87/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0111 - acc: 0.8070 - val_loss: 1.0458 - val_acc: 0.8018\n",
      "Epoch 88/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0076 - acc: 0.7974 - val_loss: 1.0417 - val_acc: 0.7530\n",
      "Epoch 89/400\n",
      "750000/750000 [==============================] - 5s - loss: 1.0042 - acc: 0.7875 - val_loss: 1.0319 - val_acc: 0.8185\n",
      "Epoch 90/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9976 - acc: 0.8016 - val_loss: 1.0301 - val_acc: 0.8091\n",
      "Epoch 91/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9942 - acc: 0.8058 - val_loss: 1.0256 - val_acc: 0.8261\n",
      "Epoch 92/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9885 - acc: 0.8108 - val_loss: 1.0324 - val_acc: 0.7405\n",
      "Epoch 93/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9861 - acc: 0.8002 - val_loss: 1.0112 - val_acc: 0.8200\n",
      "Epoch 94/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9804 - acc: 0.8177 - val_loss: 1.0084 - val_acc: 0.7714\n",
      "Epoch 95/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9763 - acc: 0.8024 - val_loss: 1.0070 - val_acc: 0.7864\n",
      "Epoch 96/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9710 - acc: 0.8096 - val_loss: 0.9966 - val_acc: 0.8004\n",
      "Epoch 97/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9665 - acc: 0.8070 - val_loss: 0.9997 - val_acc: 0.8009\n",
      "Epoch 98/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9617 - acc: 0.8112 - val_loss: 0.9931 - val_acc: 0.8002\n",
      "Epoch 99/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9606 - acc: 0.7969 - val_loss: 0.9897 - val_acc: 0.8005\n",
      "Epoch 100/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9563 - acc: 0.7943 - val_loss: 0.9881 - val_acc: 0.7861\n",
      "Epoch 101/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9515 - acc: 0.8097 - val_loss: 0.9822 - val_acc: 0.7962\n",
      "Epoch 102/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9459 - acc: 0.8185 - val_loss: 0.9726 - val_acc: 0.8031\n",
      "Epoch 103/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9387 - acc: 0.8261 - val_loss: 0.9815 - val_acc: 0.8063\n",
      "Epoch 104/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9390 - acc: 0.8030 - val_loss: 0.9762 - val_acc: 0.7741\n",
      "Epoch 105/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9371 - acc: 0.7923 - val_loss: 0.9654 - val_acc: 0.7673\n",
      "Epoch 106/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9293 - acc: 0.8153 - val_loss: 0.9550 - val_acc: 0.8186\n",
      "Epoch 107/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9269 - acc: 0.8061 - val_loss: 0.9474 - val_acc: 0.8706\n",
      "Epoch 108/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9228 - acc: 0.8215 - val_loss: 0.9565 - val_acc: 0.7966\n",
      "Epoch 109/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9178 - acc: 0.8151 - val_loss: 0.9462 - val_acc: 0.8025\n",
      "Epoch 110/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9132 - acc: 0.8176 - val_loss: 0.9451 - val_acc: 0.7973\n",
      "Epoch 111/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9094 - acc: 0.8083 - val_loss: 0.9476 - val_acc: 0.7927\n",
      "Epoch 112/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9060 - acc: 0.8205 - val_loss: 0.9314 - val_acc: 0.8141\n",
      "Epoch 113/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.9029 - acc: 0.8225 - val_loss: 0.9285 - val_acc: 0.8602\n",
      "Epoch 114/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8966 - acc: 0.8252 - val_loss: 0.9277 - val_acc: 0.7948\n",
      "Epoch 115/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8954 - acc: 0.8104 - val_loss: 0.9194 - val_acc: 0.8010\n",
      "Epoch 116/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8884 - acc: 0.8288 - val_loss: 0.9237 - val_acc: 0.8264\n",
      "Epoch 117/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.8873 - acc: 0.8194 - val_loss: 0.9197 - val_acc: 0.7930\n",
      "Epoch 118/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8830 - acc: 0.8160 - val_loss: 0.9121 - val_acc: 0.7943\n",
      "Epoch 119/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8816 - acc: 0.8182 - val_loss: 0.9088 - val_acc: 0.7840\n",
      "Epoch 120/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8734 - acc: 0.8298 - val_loss: 0.9060 - val_acc: 0.7841\n",
      "Epoch 121/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8718 - acc: 0.8180 - val_loss: 0.9103 - val_acc: 0.7381\n",
      "Epoch 122/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8727 - acc: 0.8004 - val_loss: 0.8987 - val_acc: 0.7959\n",
      "Epoch 123/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8663 - acc: 0.8252 - val_loss: 0.8927 - val_acc: 0.8335\n",
      "Epoch 124/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8614 - acc: 0.8301 - val_loss: 0.8938 - val_acc: 0.8384\n",
      "Epoch 125/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8606 - acc: 0.8239 - val_loss: 0.8820 - val_acc: 0.8313\n",
      "Epoch 126/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8539 - acc: 0.8224 - val_loss: 0.8854 - val_acc: 0.8396\n",
      "Epoch 127/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8510 - acc: 0.8246 - val_loss: 0.8765 - val_acc: 0.8563\n",
      "Epoch 128/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8480 - acc: 0.8205 - val_loss: 0.8780 - val_acc: 0.8060\n",
      "Epoch 129/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8407 - acc: 0.8453 - val_loss: 0.8781 - val_acc: 0.7867\n",
      "Epoch 130/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8364 - acc: 0.8483 - val_loss: 0.8625 - val_acc: 0.8428\n",
      "Epoch 131/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8338 - acc: 0.8411 - val_loss: 0.8760 - val_acc: 0.7881\n",
      "Epoch 132/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8306 - acc: 0.8385 - val_loss: 0.8616 - val_acc: 0.8180\n",
      "Epoch 133/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8271 - acc: 0.8352 - val_loss: 0.8662 - val_acc: 0.8051\n",
      "Epoch 134/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8252 - acc: 0.8372 - val_loss: 0.8536 - val_acc: 0.8186\n",
      "Epoch 135/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8240 - acc: 0.8287 - val_loss: 0.8464 - val_acc: 0.8312\n",
      "Epoch 136/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8208 - acc: 0.8324 - val_loss: 0.8593 - val_acc: 0.7982\n",
      "Epoch 137/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8203 - acc: 0.8233 - val_loss: 0.8475 - val_acc: 0.8268\n",
      "Epoch 138/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.8133 - acc: 0.8324 - val_loss: 0.8527 - val_acc: 0.8198\n",
      "Epoch 139/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.8138 - acc: 0.8253 - val_loss: 0.8434 - val_acc: 0.8151\n",
      "Epoch 140/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.8054 - acc: 0.8570 - val_loss: 0.8335 - val_acc: 0.8523\n",
      "Epoch 141/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.8031 - acc: 0.8416 - val_loss: 0.8371 - val_acc: 0.8377\n",
      "Epoch 142/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.8003 - acc: 0.8416 - val_loss: 0.8355 - val_acc: 0.8578\n",
      "Epoch 143/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.7982 - acc: 0.8520 - val_loss: 0.8244 - val_acc: 0.8407\n",
      "Epoch 144/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.7950 - acc: 0.8426 - val_loss: 0.8206 - val_acc: 0.8494\n",
      "Epoch 145/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7914 - acc: 0.8514 - val_loss: 0.8226 - val_acc: 0.8239\n",
      "Epoch 146/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.7899 - acc: 0.8356 - val_loss: 0.8308 - val_acc: 0.8314\n",
      "Epoch 147/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7888 - acc: 0.8257 - val_loss: 0.8153 - val_acc: 0.8070\n",
      "Epoch 148/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7825 - acc: 0.8445 - val_loss: 0.8126 - val_acc: 0.8419\n",
      "Epoch 149/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7769 - acc: 0.8573 - val_loss: 0.8046 - val_acc: 0.8641\n",
      "Epoch 150/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7739 - acc: 0.8606 - val_loss: 0.8015 - val_acc: 0.8503\n",
      "Epoch 151/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7708 - acc: 0.8611 - val_loss: 0.8071 - val_acc: 0.8404\n",
      "Epoch 152/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7678 - acc: 0.8671 - val_loss: 0.8029 - val_acc: 0.8503\n",
      "Epoch 153/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7684 - acc: 0.8527 - val_loss: 0.8095 - val_acc: 0.8417\n",
      "Epoch 154/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7695 - acc: 0.8408 - val_loss: 0.8081 - val_acc: 0.8351\n",
      "Epoch 155/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.7672 - acc: 0.8213 - val_loss: 0.7987 - val_acc: 0.8112\n",
      "Epoch 156/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.7600 - acc: 0.8384 - val_loss: 0.7949 - val_acc: 0.8306\n",
      "Epoch 157/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.7557 - acc: 0.8534 - val_loss: 0.8010 - val_acc: 0.8290\n",
      "Epoch 158/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7564 - acc: 0.8487 - val_loss: 0.7848 - val_acc: 0.8378\n",
      "Epoch 159/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7523 - acc: 0.8451 - val_loss: 0.7791 - val_acc: 0.8546\n",
      "Epoch 160/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7504 - acc: 0.8511 - val_loss: 0.7760 - val_acc: 0.8689\n",
      "Epoch 161/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7457 - acc: 0.8568 - val_loss: 0.7695 - val_acc: 0.8672\n",
      "Epoch 162/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7434 - acc: 0.8539 - val_loss: 0.7767 - val_acc: 0.8695\n",
      "Epoch 163/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7467 - acc: 0.8341 - val_loss: 0.7780 - val_acc: 0.8231\n",
      "Epoch 164/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7394 - acc: 0.8563 - val_loss: 0.7608 - val_acc: 0.8777\n",
      "Epoch 165/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7333 - acc: 0.8624 - val_loss: 0.7667 - val_acc: 0.8455\n",
      "Epoch 166/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7328 - acc: 0.8629 - val_loss: 0.7609 - val_acc: 0.8815\n",
      "Epoch 167/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7291 - acc: 0.8572 - val_loss: 0.7554 - val_acc: 0.8693\n",
      "Epoch 168/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7265 - acc: 0.8626 - val_loss: 0.7601 - val_acc: 0.8489\n",
      "Epoch 169/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7235 - acc: 0.8637 - val_loss: 0.7621 - val_acc: 0.8259\n",
      "Epoch 170/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7229 - acc: 0.8568 - val_loss: 0.7551 - val_acc: 0.8178\n",
      "Epoch 171/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7211 - acc: 0.8561 - val_loss: 0.7554 - val_acc: 0.8496\n",
      "Epoch 172/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.7179 - acc: 0.8633 - val_loss: 0.7584 - val_acc: 0.8263\n",
      "Epoch 173/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7189 - acc: 0.8498 - val_loss: 0.7586 - val_acc: 0.8308\n",
      "Epoch 174/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7173 - acc: 0.8457 - val_loss: 0.7464 - val_acc: 0.8290\n",
      "Epoch 175/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7090 - acc: 0.8566 - val_loss: 0.7346 - val_acc: 0.8923\n",
      "Epoch 176/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7083 - acc: 0.8616 - val_loss: 0.7445 - val_acc: 0.8397\n",
      "Epoch 177/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7065 - acc: 0.8492 - val_loss: 0.7498 - val_acc: 0.8093\n",
      "Epoch 178/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.7027 - acc: 0.8586 - val_loss: 0.7329 - val_acc: 0.8541\n",
      "Epoch 179/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6986 - acc: 0.8785 - val_loss: 0.7279 - val_acc: 0.8691\n",
      "Epoch 180/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6953 - acc: 0.8753 - val_loss: 0.7340 - val_acc: 0.8331\n",
      "Epoch 181/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6939 - acc: 0.8681 - val_loss: 0.7265 - val_acc: 0.8780\n",
      "Epoch 182/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6969 - acc: 0.8579 - val_loss: 0.7302 - val_acc: 0.8600\n",
      "Epoch 183/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6939 - acc: 0.8636 - val_loss: 0.7307 - val_acc: 0.8560\n",
      "Epoch 184/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6929 - acc: 0.8507 - val_loss: 0.7316 - val_acc: 0.8199\n",
      "Epoch 185/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6897 - acc: 0.8656 - val_loss: 0.7210 - val_acc: 0.8381\n",
      "Epoch 186/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6820 - acc: 0.8801 - val_loss: 0.7172 - val_acc: 0.8540\n",
      "Epoch 187/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6787 - acc: 0.8885 - val_loss: 0.7287 - val_acc: 0.8029\n",
      "Epoch 188/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6817 - acc: 0.8678 - val_loss: 0.7104 - val_acc: 0.8858\n",
      "Epoch 189/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6753 - acc: 0.8843 - val_loss: 0.7010 - val_acc: 0.8691\n",
      "Epoch 190/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6761 - acc: 0.8714 - val_loss: 0.7117 - val_acc: 0.8380\n",
      "Epoch 191/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6754 - acc: 0.8674 - val_loss: 0.7092 - val_acc: 0.8503\n",
      "Epoch 192/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6744 - acc: 0.8617 - val_loss: 0.7126 - val_acc: 0.8645\n",
      "Epoch 193/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6706 - acc: 0.8785 - val_loss: 0.6953 - val_acc: 0.8634\n",
      "Epoch 194/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6651 - acc: 0.8815 - val_loss: 0.6918 - val_acc: 0.8665\n",
      "Epoch 195/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6664 - acc: 0.8683 - val_loss: 0.6923 - val_acc: 0.8775\n",
      "Epoch 196/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6618 - acc: 0.8823 - val_loss: 0.6933 - val_acc: 0.8774\n",
      "Epoch 197/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6587 - acc: 0.8851 - val_loss: 0.6976 - val_acc: 0.8818\n",
      "Epoch 198/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6578 - acc: 0.8724 - val_loss: 0.6852 - val_acc: 0.8915\n",
      "Epoch 199/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6556 - acc: 0.8811 - val_loss: 0.6879 - val_acc: 0.8844\n",
      "Epoch 200/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6572 - acc: 0.8834 - val_loss: 0.6883 - val_acc: 0.8517\n",
      "Epoch 201/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6597 - acc: 0.8549 - val_loss: 0.6828 - val_acc: 0.8706\n",
      "Epoch 202/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6496 - acc: 0.8754 - val_loss: 0.6887 - val_acc: 0.8709\n",
      "Epoch 203/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6468 - acc: 0.8844 - val_loss: 0.6776 - val_acc: 0.8899\n",
      "Epoch 204/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6409 - acc: 0.8924 - val_loss: 0.6652 - val_acc: 0.8996\n",
      "Epoch 205/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6413 - acc: 0.8847 - val_loss: 0.6724 - val_acc: 0.8778\n",
      "Epoch 206/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6422 - acc: 0.8841 - val_loss: 0.6705 - val_acc: 0.8846\n",
      "Epoch 207/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6410 - acc: 0.8888 - val_loss: 0.6859 - val_acc: 0.8399\n",
      "Epoch 208/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6461 - acc: 0.8535 - val_loss: 0.6729 - val_acc: 0.8246\n",
      "Epoch 209/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6366 - acc: 0.8821 - val_loss: 0.6718 - val_acc: 0.8831\n",
      "Epoch 210/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6381 - acc: 0.8775 - val_loss: 0.6688 - val_acc: 0.8768\n",
      "Epoch 211/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6347 - acc: 0.8795 - val_loss: 0.6623 - val_acc: 0.8776\n",
      "Epoch 212/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6273 - acc: 0.8934 - val_loss: 0.6699 - val_acc: 0.8797\n",
      "Epoch 213/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6320 - acc: 0.8658 - val_loss: 0.6566 - val_acc: 0.8844\n",
      "Epoch 214/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6287 - acc: 0.8769 - val_loss: 0.6663 - val_acc: 0.8616\n",
      "Epoch 215/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6256 - acc: 0.8901 - val_loss: 0.6527 - val_acc: 0.8915\n",
      "Epoch 216/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6195 - acc: 0.8934 - val_loss: 0.6559 - val_acc: 0.8897\n",
      "Epoch 217/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6182 - acc: 0.9006 - val_loss: 0.6456 - val_acc: 0.9015\n",
      "Epoch 218/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6146 - acc: 0.9065 - val_loss: 0.6503 - val_acc: 0.8805\n",
      "Epoch 219/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6187 - acc: 0.8826 - val_loss: 0.6542 - val_acc: 0.8595\n",
      "Epoch 220/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6167 - acc: 0.8807 - val_loss: 0.6484 - val_acc: 0.9073\n",
      "Epoch 221/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6136 - acc: 0.8895 - val_loss: 0.6468 - val_acc: 0.9021\n",
      "Epoch 222/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6110 - acc: 0.8935 - val_loss: 0.6426 - val_acc: 0.8780\n",
      "Epoch 223/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6082 - acc: 0.8923 - val_loss: 0.6376 - val_acc: 0.8929\n",
      "Epoch 224/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6085 - acc: 0.8957 - val_loss: 0.6454 - val_acc: 0.8671\n",
      "Epoch 225/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6096 - acc: 0.8902 - val_loss: 0.6462 - val_acc: 0.8854\n",
      "Epoch 226/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.6042 - acc: 0.8929 - val_loss: 0.6319 - val_acc: 0.9206\n",
      "Epoch 227/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6043 - acc: 0.8928 - val_loss: 0.6310 - val_acc: 0.8929\n",
      "Epoch 228/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6071 - acc: 0.8841 - val_loss: 0.6358 - val_acc: 0.8595\n",
      "Epoch 229/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6021 - acc: 0.8859 - val_loss: 0.6291 - val_acc: 0.8817\n",
      "Epoch 230/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.6004 - acc: 0.8861 - val_loss: 0.6341 - val_acc: 0.8819\n",
      "Epoch 231/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5972 - acc: 0.8944 - val_loss: 0.6178 - val_acc: 0.9166\n",
      "Epoch 232/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5927 - acc: 0.8989 - val_loss: 0.6220 - val_acc: 0.9047\n",
      "Epoch 233/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5899 - acc: 0.9054 - val_loss: 0.6243 - val_acc: 0.8892\n",
      "Epoch 234/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5910 - acc: 0.8917 - val_loss: 0.6205 - val_acc: 0.9039\n",
      "Epoch 235/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5890 - acc: 0.9065 - val_loss: 0.6182 - val_acc: 0.8991\n",
      "Epoch 236/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5864 - acc: 0.9099 - val_loss: 0.6160 - val_acc: 0.8874\n",
      "Epoch 237/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5861 - acc: 0.8940 - val_loss: 0.6177 - val_acc: 0.9031\n",
      "Epoch 238/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5846 - acc: 0.9009 - val_loss: 0.6204 - val_acc: 0.8808\n",
      "Epoch 239/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5844 - acc: 0.9007 - val_loss: 0.6029 - val_acc: 0.9328\n",
      "Epoch 240/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5799 - acc: 0.9008 - val_loss: 0.6105 - val_acc: 0.8965\n",
      "Epoch 241/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5804 - acc: 0.8933 - val_loss: 0.6140 - val_acc: 0.8617\n",
      "Epoch 242/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5815 - acc: 0.8896 - val_loss: 0.6069 - val_acc: 0.8915\n",
      "Epoch 243/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5743 - acc: 0.9097 - val_loss: 0.5953 - val_acc: 0.9327\n",
      "Epoch 244/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5713 - acc: 0.9137 - val_loss: 0.6041 - val_acc: 0.8833\n",
      "Epoch 245/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5718 - acc: 0.8997 - val_loss: 0.6049 - val_acc: 0.8928\n",
      "Epoch 246/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5739 - acc: 0.8977 - val_loss: 0.6093 - val_acc: 0.8984\n",
      "Epoch 247/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5733 - acc: 0.8956 - val_loss: 0.6042 - val_acc: 0.8866\n",
      "Epoch 248/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5727 - acc: 0.8887 - val_loss: 0.5999 - val_acc: 0.9215\n",
      "Epoch 249/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5692 - acc: 0.8972 - val_loss: 0.6026 - val_acc: 0.9014\n",
      "Epoch 250/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5660 - acc: 0.9044 - val_loss: 0.5865 - val_acc: 0.9462\n",
      "Epoch 251/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5642 - acc: 0.9004 - val_loss: 0.5937 - val_acc: 0.8809\n",
      "Epoch 252/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5615 - acc: 0.9026 - val_loss: 0.6027 - val_acc: 0.8822\n",
      "Epoch 253/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5602 - acc: 0.9055 - val_loss: 0.5936 - val_acc: 0.8882\n",
      "Epoch 254/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5600 - acc: 0.8994 - val_loss: 0.5862 - val_acc: 0.8976\n",
      "Epoch 255/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5596 - acc: 0.8934 - val_loss: 0.5845 - val_acc: 0.9170\n",
      "Epoch 256/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5528 - acc: 0.9189 - val_loss: 0.5944 - val_acc: 0.8912\n",
      "Epoch 257/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5565 - acc: 0.8958 - val_loss: 0.5979 - val_acc: 0.8646\n",
      "Epoch 258/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5630 - acc: 0.8783 - val_loss: 0.6019 - val_acc: 0.8671\n",
      "Epoch 259/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5596 - acc: 0.8905 - val_loss: 0.5824 - val_acc: 0.9132\n",
      "Epoch 260/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5526 - acc: 0.8972 - val_loss: 0.5749 - val_acc: 0.9391\n",
      "Epoch 261/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5469 - acc: 0.9098 - val_loss: 0.5812 - val_acc: 0.8965\n",
      "Epoch 262/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5484 - acc: 0.9018 - val_loss: 0.5747 - val_acc: 0.8971\n",
      "Epoch 263/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5456 - acc: 0.9033 - val_loss: 0.5708 - val_acc: 0.9186\n",
      "Epoch 264/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5435 - acc: 0.9152 - val_loss: 0.5754 - val_acc: 0.9282\n",
      "Epoch 265/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5450 - acc: 0.9119 - val_loss: 0.5834 - val_acc: 0.8746\n",
      "Epoch 266/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5477 - acc: 0.8971 - val_loss: 0.5722 - val_acc: 0.9036\n",
      "Epoch 267/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5413 - acc: 0.9018 - val_loss: 0.5627 - val_acc: 0.9324\n",
      "Epoch 268/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5377 - acc: 0.9058 - val_loss: 0.5663 - val_acc: 0.9070\n",
      "Epoch 269/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5360 - acc: 0.9133 - val_loss: 0.5786 - val_acc: 0.8938\n",
      "Epoch 270/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5383 - acc: 0.9025 - val_loss: 0.5699 - val_acc: 0.8928\n",
      "Epoch 271/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5376 - acc: 0.9085 - val_loss: 0.5791 - val_acc: 0.8783\n",
      "Epoch 272/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5334 - acc: 0.9163 - val_loss: 0.5689 - val_acc: 0.9089\n",
      "Epoch 273/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5318 - acc: 0.9156 - val_loss: 0.5633 - val_acc: 0.9185\n",
      "Epoch 274/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5327 - acc: 0.9135 - val_loss: 0.5590 - val_acc: 0.9070\n",
      "Epoch 275/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5280 - acc: 0.9122 - val_loss: 0.5579 - val_acc: 0.8987\n",
      "Epoch 276/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5299 - acc: 0.9106 - val_loss: 0.5715 - val_acc: 0.8888\n",
      "Epoch 277/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5219 - acc: 0.9241 - val_loss: 0.5558 - val_acc: 0.9440\n",
      "Epoch 278/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5210 - acc: 0.9234 - val_loss: 0.5586 - val_acc: 0.8791\n",
      "Epoch 279/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5240 - acc: 0.9122 - val_loss: 0.5548 - val_acc: 0.9273\n",
      "Epoch 280/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5250 - acc: 0.9025 - val_loss: 0.5510 - val_acc: 0.9243\n",
      "Epoch 281/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5210 - acc: 0.9148 - val_loss: 0.5530 - val_acc: 0.9093\n",
      "Epoch 282/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5245 - acc: 0.9017 - val_loss: 0.5625 - val_acc: 0.9094\n",
      "Epoch 283/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5213 - acc: 0.9092 - val_loss: 0.5480 - val_acc: 0.9152\n",
      "Epoch 284/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5154 - acc: 0.9188 - val_loss: 0.5397 - val_acc: 0.9408\n",
      "Epoch 285/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5133 - acc: 0.9250 - val_loss: 0.5488 - val_acc: 0.8884\n",
      "Epoch 286/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5207 - acc: 0.8987 - val_loss: 0.5531 - val_acc: 0.8632\n",
      "Epoch 287/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5184 - acc: 0.8980 - val_loss: 0.5388 - val_acc: 0.9219\n",
      "Epoch 288/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5143 - acc: 0.9086 - val_loss: 0.5497 - val_acc: 0.8772\n",
      "Epoch 289/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5177 - acc: 0.8955 - val_loss: 0.5350 - val_acc: 0.9296\n",
      "Epoch 290/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5112 - acc: 0.9224 - val_loss: 0.5445 - val_acc: 0.9031\n",
      "Epoch 291/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5084 - acc: 0.9258 - val_loss: 0.5392 - val_acc: 0.9069\n",
      "Epoch 292/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5044 - acc: 0.9237 - val_loss: 0.5488 - val_acc: 0.8899\n",
      "Epoch 293/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5045 - acc: 0.9237 - val_loss: 0.5309 - val_acc: 0.9578\n",
      "Epoch 294/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5043 - acc: 0.9234 - val_loss: 0.5301 - val_acc: 0.9178\n",
      "Epoch 295/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5052 - acc: 0.9203 - val_loss: 0.5279 - val_acc: 0.9403\n",
      "Epoch 296/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5018 - acc: 0.9283 - val_loss: 0.5326 - val_acc: 0.8915\n",
      "Epoch 297/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5063 - acc: 0.9061 - val_loss: 0.5398 - val_acc: 0.9199\n",
      "Epoch 298/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4994 - acc: 0.9252 - val_loss: 0.5354 - val_acc: 0.9212\n",
      "Epoch 299/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5030 - acc: 0.9109 - val_loss: 0.5324 - val_acc: 0.9117\n",
      "Epoch 300/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4974 - acc: 0.9126 - val_loss: 0.5373 - val_acc: 0.9126\n",
      "Epoch 301/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.5007 - acc: 0.9043 - val_loss: 0.5306 - val_acc: 0.8962\n",
      "Epoch 302/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4995 - acc: 0.9067 - val_loss: 0.5253 - val_acc: 0.9293\n",
      "Epoch 303/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4956 - acc: 0.9231 - val_loss: 0.5135 - val_acc: 0.9318\n",
      "Epoch 304/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4907 - acc: 0.9283 - val_loss: 0.5200 - val_acc: 0.9222\n",
      "Epoch 305/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4895 - acc: 0.9258 - val_loss: 0.5196 - val_acc: 0.9173\n",
      "Epoch 306/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4874 - acc: 0.9232 - val_loss: 0.5240 - val_acc: 0.9302\n",
      "Epoch 307/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4838 - acc: 0.9425 - val_loss: 0.5194 - val_acc: 0.9537\n",
      "Epoch 308/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4907 - acc: 0.9184 - val_loss: 0.5240 - val_acc: 0.9343\n",
      "Epoch 309/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4893 - acc: 0.9168 - val_loss: 0.5343 - val_acc: 0.8741\n",
      "Epoch 310/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4873 - acc: 0.9153 - val_loss: 0.5182 - val_acc: 0.9170\n",
      "Epoch 311/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4862 - acc: 0.9114 - val_loss: 0.5120 - val_acc: 0.9523\n",
      "Epoch 312/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4869 - acc: 0.9166 - val_loss: 0.5116 - val_acc: 0.9223\n",
      "Epoch 313/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4794 - acc: 0.9233 - val_loss: 0.5218 - val_acc: 0.8934\n",
      "Epoch 314/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4824 - acc: 0.9124 - val_loss: 0.5122 - val_acc: 0.9446\n",
      "Epoch 315/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4766 - acc: 0.9398 - val_loss: 0.5000 - val_acc: 0.9599\n",
      "Epoch 316/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4764 - acc: 0.9233 - val_loss: 0.5070 - val_acc: 0.9230\n",
      "Epoch 317/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4816 - acc: 0.9150 - val_loss: 0.5238 - val_acc: 0.9088\n",
      "Epoch 318/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4931 - acc: 0.8947 - val_loss: 0.5468 - val_acc: 0.8581\n",
      "Epoch 319/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4924 - acc: 0.8979 - val_loss: 0.5523 - val_acc: 0.9068\n",
      "Epoch 320/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.5080 - acc: 0.9022 - val_loss: 0.5175 - val_acc: 0.9079\n",
      "Epoch 321/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4930 - acc: 0.9047 - val_loss: 0.5081 - val_acc: 0.9084\n",
      "Epoch 322/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4764 - acc: 0.9309 - val_loss: 0.5207 - val_acc: 0.9144\n",
      "Epoch 323/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4714 - acc: 0.9331 - val_loss: 0.4949 - val_acc: 0.9303\n",
      "Epoch 324/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4650 - acc: 0.9339 - val_loss: 0.5028 - val_acc: 0.9083\n",
      "Epoch 325/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4731 - acc: 0.9215 - val_loss: 0.5032 - val_acc: 0.9287\n",
      "Epoch 326/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4674 - acc: 0.9317 - val_loss: 0.4987 - val_acc: 0.9314\n",
      "Epoch 327/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4653 - acc: 0.9322 - val_loss: 0.4936 - val_acc: 0.9462\n",
      "Epoch 328/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4629 - acc: 0.9415 - val_loss: 0.4979 - val_acc: 0.8986\n",
      "Epoch 329/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4692 - acc: 0.9130 - val_loss: 0.4909 - val_acc: 0.9199\n",
      "Epoch 330/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4672 - acc: 0.9195 - val_loss: 0.4983 - val_acc: 0.9070\n",
      "Epoch 331/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4643 - acc: 0.9233 - val_loss: 0.4964 - val_acc: 0.9219\n",
      "Epoch 332/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4582 - acc: 0.9372 - val_loss: 0.4925 - val_acc: 0.9247\n",
      "Epoch 333/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4603 - acc: 0.9280 - val_loss: 0.4906 - val_acc: 0.9522\n",
      "Epoch 334/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4569 - acc: 0.9345 - val_loss: 0.4891 - val_acc: 0.9405\n",
      "Epoch 335/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4568 - acc: 0.9300 - val_loss: 0.4905 - val_acc: 0.9269\n",
      "Epoch 336/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4579 - acc: 0.9265 - val_loss: 0.4863 - val_acc: 0.9420\n",
      "Epoch 337/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4554 - acc: 0.9396 - val_loss: 0.4834 - val_acc: 0.9445\n",
      "Epoch 338/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4513 - acc: 0.9388 - val_loss: 0.4856 - val_acc: 0.9468\n",
      "Epoch 339/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4528 - acc: 0.9355 - val_loss: 0.4928 - val_acc: 0.8813\n",
      "Epoch 340/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4544 - acc: 0.9217 - val_loss: 0.4897 - val_acc: 0.9147\n",
      "Epoch 341/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4525 - acc: 0.9378 - val_loss: 0.4797 - val_acc: 0.9413\n",
      "Epoch 342/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4495 - acc: 0.9322 - val_loss: 0.4851 - val_acc: 0.9228\n",
      "Epoch 343/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4501 - acc: 0.9328 - val_loss: 0.4800 - val_acc: 0.9332\n",
      "Epoch 344/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4539 - acc: 0.9178 - val_loss: 0.4805 - val_acc: 0.9238\n",
      "Epoch 345/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4475 - acc: 0.9349 - val_loss: 0.4801 - val_acc: 0.9220\n",
      "Epoch 346/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4515 - acc: 0.9216 - val_loss: 0.4745 - val_acc: 0.9516\n",
      "Epoch 347/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4462 - acc: 0.9366 - val_loss: 0.4720 - val_acc: 0.9506\n",
      "Epoch 348/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4429 - acc: 0.9467 - val_loss: 0.4718 - val_acc: 0.9352\n",
      "Epoch 349/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4420 - acc: 0.9381 - val_loss: 0.4699 - val_acc: 0.9549\n",
      "Epoch 350/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4412 - acc: 0.9400 - val_loss: 0.4816 - val_acc: 0.9456\n",
      "Epoch 351/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4431 - acc: 0.9375 - val_loss: 0.4840 - val_acc: 0.8886\n",
      "Epoch 352/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4556 - acc: 0.9029 - val_loss: 0.4759 - val_acc: 0.9137\n",
      "Epoch 353/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4513 - acc: 0.9053 - val_loss: 0.4833 - val_acc: 0.9098\n",
      "Epoch 354/400\n",
      "750000/750000 [==============================] - 5s - loss: 0.4436 - acc: 0.9291 - val_loss: 0.4795 - val_acc: 0.8951\n",
      "Epoch 355/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4452 - acc: 0.9175 - val_loss: 0.4713 - val_acc: 0.9140\n",
      "Epoch 356/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4371 - acc: 0.9363 - val_loss: 0.4708 - val_acc: 0.9222\n",
      "Epoch 357/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4368 - acc: 0.9295 - val_loss: 0.4707 - val_acc: 0.9082\n",
      "Epoch 358/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4398 - acc: 0.9272 - val_loss: 0.4721 - val_acc: 0.9350\n",
      "Epoch 359/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4286 - acc: 0.9535 - val_loss: 0.4562 - val_acc: 0.9560\n",
      "Epoch 360/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4276 - acc: 0.9473 - val_loss: 0.4660 - val_acc: 0.9389\n",
      "Epoch 361/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4356 - acc: 0.9313 - val_loss: 0.4766 - val_acc: 0.9122\n",
      "Epoch 362/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4400 - acc: 0.9288 - val_loss: 0.4772 - val_acc: 0.9448\n",
      "Epoch 363/400\n",
      "750000/750000 [==============================] - 4s - loss: 0.4360 - acc: 0.9363 - val_loss: 0.4690 - val_acc: 0.9409\n",
      "Epoch 364/400\n",
      "750000/750000 [==============================] - 4s - loss: 2.8458 - acc: 0.5399 - val_loss: 4.5226 - val_acc: 0.3706\n",
      "Epoch 365/400\n",
      "750000/750000 [==============================] - 4s - loss: 4.4199 - acc: 0.4394 - val_loss: 3.9949 - val_acc: 0.5236\n",
      "Epoch 366/400\n",
      "750000/750000 [==============================] - 4s - loss: 3.9823 - acc: 0.5869 - val_loss: 3.8536 - val_acc: 0.6162\n",
      "Epoch 367/400\n",
      "750000/750000 [==============================] - 4s - loss: 3.8271 - acc: 0.6728 - val_loss: 3.7280 - val_acc: 0.7166\n",
      "Epoch 368/400\n",
      "750000/750000 [==============================] - 4s - loss: 3.6834 - acc: 0.7275 - val_loss: 3.5885 - val_acc: 0.7461\n",
      "Epoch 369/400\n",
      "750000/750000 [==============================] - 4s - loss: 3.6486 - acc: 0.7644 - val_loss: 3.5795 - val_acc: 0.7607\n",
      "Epoch 370/400\n",
      "750000/750000 [==============================] - 4s - loss: 3.6465 - acc: 0.7647 - val_loss: 3.5833 - val_acc: 0.7615\n",
      "Epoch 371/400\n",
      "750000/750000 [==============================] - 4s - loss: 3.6462 - acc: 0.7613 - val_loss: 3.5785 - val_acc: 0.7742\n",
      "Epoch 372/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6463 - acc: 0.7651 - val_loss: 3.5800 - val_acc: 0.7451\n",
      "Epoch 373/400\n",
      "750000/750000 [==============================] - 4s - loss: 3.6466 - acc: 0.7618 - val_loss: 3.5795 - val_acc: 0.7509\n",
      "Epoch 374/400\n",
      "750000/750000 [==============================] - 4s - loss: 3.6486 - acc: 0.7521 - val_loss: 3.5840 - val_acc: 0.7588\n",
      "Epoch 375/400\n",
      "750000/750000 [==============================] - 4s - loss: 3.6466 - acc: 0.7562 - val_loss: 3.5791 - val_acc: 0.7666\n",
      "Epoch 376/400\n",
      "750000/750000 [==============================] - 4s - loss: 3.6447 - acc: 0.7656 - val_loss: 3.5733 - val_acc: 0.7881\n",
      "Epoch 377/400\n",
      "750000/750000 [==============================] - 4s - loss: 3.6441 - acc: 0.7641 - val_loss: 3.5753 - val_acc: 0.7546\n",
      "Epoch 378/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6432 - acc: 0.7595 - val_loss: 3.5785 - val_acc: 0.7444\n",
      "Epoch 379/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6440 - acc: 0.7604 - val_loss: 3.5862 - val_acc: 0.7303\n",
      "Epoch 380/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6479 - acc: 0.7452 - val_loss: 3.5776 - val_acc: 0.7693\n",
      "Epoch 381/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6443 - acc: 0.7563 - val_loss: 3.5790 - val_acc: 0.7430\n",
      "Epoch 382/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6438 - acc: 0.7563 - val_loss: 3.5783 - val_acc: 0.7637\n",
      "Epoch 383/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6422 - acc: 0.7611 - val_loss: 3.5695 - val_acc: 0.7865\n",
      "Epoch 384/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6407 - acc: 0.7570 - val_loss: 3.5753 - val_acc: 0.7417\n",
      "Epoch 385/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6401 - acc: 0.7617 - val_loss: 3.5696 - val_acc: 0.7725\n",
      "Epoch 386/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6427 - acc: 0.7534 - val_loss: 3.5780 - val_acc: 0.7534\n",
      "Epoch 387/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6401 - acc: 0.7602 - val_loss: 3.5705 - val_acc: 0.7772\n",
      "Epoch 388/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6396 - acc: 0.7569 - val_loss: 3.5727 - val_acc: 0.7588\n",
      "Epoch 389/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6368 - acc: 0.7657 - val_loss: 3.5683 - val_acc: 0.7747\n",
      "Epoch 390/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6361 - acc: 0.7654 - val_loss: 3.5739 - val_acc: 0.7422\n",
      "Epoch 391/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6380 - acc: 0.7582 - val_loss: 3.5668 - val_acc: 0.7681\n",
      "Epoch 392/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6378 - acc: 0.7589 - val_loss: 3.5733 - val_acc: 0.7727\n",
      "Epoch 393/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6380 - acc: 0.7552 - val_loss: 3.5704 - val_acc: 0.7649\n",
      "Epoch 394/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6354 - acc: 0.7566 - val_loss: 3.5698 - val_acc: 0.7505\n",
      "Epoch 395/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6372 - acc: 0.7503 - val_loss: 3.5705 - val_acc: 0.7553\n",
      "Epoch 396/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6359 - acc: 0.7546 - val_loss: 3.5629 - val_acc: 0.7629\n",
      "Epoch 397/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6364 - acc: 0.7476 - val_loss: 3.5704 - val_acc: 0.7604\n",
      "Epoch 398/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6372 - acc: 0.7460 - val_loss: 3.5690 - val_acc: 0.7571\n",
      "Epoch 399/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6375 - acc: 0.7435 - val_loss: 3.5680 - val_acc: 0.7556\n",
      "Epoch 400/400\n",
      "750000/750000 [==============================] - 5s - loss: 3.6401 - acc: 0.7374 - val_loss: 3.5727 - val_acc: 0.7289\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, \n",
    "                    batch_size = batch_sizes, \n",
    "                    epochs = train_epochs, verbose = 1, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_train(hist):\n",
    "    h = hist.history\n",
    "    if 'acc' in h:\n",
    "        meas='acc'\n",
    "        loc='lower right'\n",
    "    else:\n",
    "        meas='loss'\n",
    "        loc='upper right'\n",
    "    plt.plot(hist.history[meas])\n",
    "    plt.plot(hist.history['val_'+meas])\n",
    "    plt.title('model '+meas)\n",
    "    plt.ylabel(meas)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc=loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6jPxWLUq8S0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a61ed44668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Evaluate the model, save the model and do the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.57274367876\n",
      "Test accuracy: 0.728904\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% prediction accuracy 1 -  69.3\n"
     ]
    }
   ],
   "source": [
    "# Do prediction test on random data\n",
    "rr = []\n",
    "numtest = 1000\n",
    "for i in range(0,numtest):\n",
    "    v3 = np.random.randint(0, x_max)\n",
    "    v4 = np.random.randint(0, y_max)\n",
    "    v6 = np.array([[v3,v4]]).astype('float32') / x_max    \n",
    "    v5=np.argmax( model.predict( v6 ) )\n",
    "    r = v5==(v3+v4)\n",
    "    rr.append(r)\n",
    "\n",
    "print(\"% prediction accuracy 1 - \", rr.count(True) / numtest * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% prediction accuracy 2 - 74.59\n"
     ]
    }
   ],
   "source": [
    "rr = []\n",
    "for i in range(0,101):\n",
    "    for j in test_list:\n",
    "        v3 = np.random.randint(0, x_max)\n",
    "        v4 = j\n",
    "        v6 = np.array([[v3,v4]]).astype('float32') / x_max    \n",
    "        v5=np.argmax( model.predict( v6 ) )\n",
    "        r = v5==(v3+v4)\n",
    "        rr.append(r)\n",
    "        \n",
    "        # swap v3 and v4 with test list\n",
    "        v3 = j\n",
    "        v4 = np.random.randint(0, x_max)\n",
    "        v6 = np.array([[v3,v4]]).astype('float32') / x_max    \n",
    "        v5=np.argmax( model.predict( v6 ) )\n",
    "        r = v5==(v3+v4)\n",
    "        rr.append(r)\n",
    "\n",
    "print(\"% prediction accuracy 2 - {0:2.2f}\".format(rr.count(True) / len(rr) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
